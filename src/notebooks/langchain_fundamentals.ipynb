{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f2b328",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Lesson 1 â€” LangChain Fundamentals for Agentic Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85392cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b467ce1",
   "metadata": {},
   "source": [
    "Before we can build an autonomous agent that can **reason** and **act**, we must first understand the basic tools used to build it.\n",
    "\n",
    "LangChain does **not** work because of one magical `\"agent\"` function.\n",
    "Its real power comes from a simple but strong idea:\n",
    "\n",
    "> **Composability**\n",
    "\n",
    "This lesson is fully dedicated to this core principle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36516203",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ”¹ Core Philosophy: Composability and LCEL\n",
    "\n",
    "LangChain is built around small components that can be **combined together**.\n",
    "Each component does **one job**, and we connect them step by step.\n",
    "\n",
    "This idea is inspired by pipelines:\n",
    "\n",
    "* input goes in,\n",
    "* transformations happen,\n",
    "* output comes out.\n",
    "\n",
    "LangChain formalizes this idea with the **LangChain Expression Language (LCEL)**.\n",
    "\n",
    "\n",
    "### ðŸ§± The Three Core Components\n",
    "\n",
    "In most LangChain applications, you will work with these three elements:\n",
    "\n",
    "* **Prompt**\n",
    "  Defines *what* we ask the model.\n",
    "\n",
    "* **Model**\n",
    "  The language model that generates the response.\n",
    "\n",
    "* **Output Parser**\n",
    "  Transforms the raw model output into a usable format.\n",
    "\n",
    "A very simple chain looks like this:\n",
    "\n",
    "```\n",
    "Prompt | Model | Output Parser\n",
    "```\n",
    "\n",
    "This is the **foundation of agentic systems**.\n",
    "Even complex agents are built by composing simple chains like this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f67f8",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Building Our First Chain with LCEL\n",
    "\n",
    "Letâ€™s now build our **first LangChain pipeline** to see composability in action.\n",
    "\n",
    "The goal is simple:\n",
    "\n",
    "> Generate a short and funny tagline for a company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9766b2",
   "metadata": {},
   "source": [
    "> âœï¸ Step 1 â€” Define the Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed546c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "promp_template = ChatPromptTemplate.from_template(\n",
    "    \"Generate a short, funny tagline for a company that makes: {topic}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da473038",
   "metadata": {},
   "source": [
    "This prompt contains a **variable** called `{topic}`.\n",
    "It allows us to reuse the same prompt with different inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabcf5bf",
   "metadata": {},
   "source": [
    "\n",
    "> ðŸ§  Step 2 â€” Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07bee149",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda2067e",
   "metadata": {},
   "source": [
    "\n",
    "* We use `gpt-4o`\n",
    "* `temperature=0` means:\n",
    "\n",
    "  * more stable\n",
    "  * more deterministic\n",
    "  * good for reproducible behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85833901",
   "metadata": {},
   "source": [
    "> ðŸ”„ Step 3 â€” Define the Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e44d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532791e",
   "metadata": {},
   "source": [
    "The model returns a complex object.\n",
    "The `StrOutputParser` extracts **only the text**, as a simple string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6970b",
   "metadata": {},
   "source": [
    "> ðŸ”— Step 4 â€” Compose the Chain with LCEL\n",
    "\n",
    "Here, we define a processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e32f43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = promp_template | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd409f12",
   "metadata": {},
   "source": [
    "- The prompt formats the input data.\n",
    "\n",
    "- The language model generates a response from that prompt.\n",
    "\n",
    "- The output parser transforms the model response into a simple string.\n",
    "\n",
    "Each component performs a single transformation.\n",
    "LCEL makes these transformations explicit and ordered.\n",
    "\n",
    "This way of composing logic is central to LangChain:\n",
    "\n",
    "- behavior is built by composition, not by inheritance,\n",
    "\n",
    "- complex systems emerge from simple, connected blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b2716",
   "metadata": {},
   "source": [
    "> â–¶ï¸ Step 5 â€” Invoke the Chain\n",
    "\n",
    "Here:\n",
    "\n",
    "* we pass the input as a dictionary\n",
    "* the chain runs from start to end\n",
    "* we receive a clean string as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ef5cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Topic: Agentic AI\n",
      "Generated Tagline: \"Agentic AI: Because even your to-do list deserves a personal assistant with a sense of humor!\"\n"
     ]
    }
   ],
   "source": [
    "topic_input = {\"topic\": \"Agentic AI\"}\n",
    "result = chain.invoke(topic_input)\n",
    "print(f\"Input Topic: {topic_input['topic']}\")\n",
    "print(f\"Generated Tagline: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7dc4a",
   "metadata": {},
   "source": [
    "At this stage, we did **not** build an agent yet.\n",
    "\n",
    "But we learned something more important:\n",
    "\n",
    "* LangChain is **modular**\n",
    "* Every agent is built from **simple chains**\n",
    "* LCEL makes data flow **explicit and readable**\n",
    "\n",
    "This pattern:\n",
    "\n",
    "```\n",
    "Prompt | Model | Output Parser\n",
    "```\n",
    "\n",
    "will appear again and again when building agentic systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd0ef4",
   "metadata": {},
   "source": [
    "## Practical LCEL â€” Piping Components Together for Inputs and Outputs\n",
    "\n",
    "In the previous section, the chain was simple:  \n",
    "one input variable â†’ one prompt â†’ one output.\n",
    "\n",
    "Real-world applications are rarely that simple.\n",
    "\n",
    "Very often, a chain must work with **several pieces of information at the same time**.\n",
    "For example:\n",
    "- a name and a description,\n",
    "- a question and some context,\n",
    "- user input and retrieved data.\n",
    "\n",
    "LCEL supports this kind of data flow through objects called **Runnables**.\n",
    "Runnables allow us to **control how information moves and transforms** inside a chain.\n",
    "\n",
    "In this section, we focus on two common Runnable patterns:\n",
    "- `RunnablePassthrough`\n",
    "- `RunnableParallel`\n",
    "\n",
    "We start with the most basic one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d71f86",
   "metadata": {},
   "source": [
    "### Handling Multiple Inputs with RunnablePassthrough\n",
    "\n",
    "The goal is simple:\n",
    "\n",
    "> Take one input dictionary and make its values available to the prompt in a clean and explicit way.\n",
    "\n",
    "We will build a small preparation step that passes data forward without modifying its meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3abaf",
   "metadata": {},
   "source": [
    "#### Step 1 â€” Define the Core Components\n",
    "\n",
    "The prompt below expects **two input variables**:\n",
    "- `{name}`\n",
    "- `{context}`\n",
    "\n",
    "Any chain using this prompt must provide both keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "795379e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"Write a short biography about {name}. \"\n",
    "    \"Focus on the following contribution: {context}. \"\n",
    "    \"Keep it light and readable.\"\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96820797",
   "metadata": {},
   "source": [
    "The prompt expects a dictionary like:\n",
    "\n",
    "```python\n",
    "{\"name\": \"...\", \"context\": \"...\"}\n",
    "```\n",
    "In practice, input data can:\n",
    "\n",
    "- come from another chain,\n",
    "\n",
    "- contain extra fields,\n",
    "\n",
    "- or be produced dynamically.\n",
    "\n",
    "So we often need an explicit preparation step to control what the prompt receives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357855f",
   "metadata": {},
   "source": [
    "#### Step 2 â€” Passing Data Forward with RunnablePassthrough Logic\n",
    "\n",
    "The idea behind `RunnablePassthrough` is simple: take the input from the previous step and make it available downstream.\n",
    "\n",
    "Here, we build a small mapping that:\n",
    "- receives the full input dictionary,\n",
    "- extracts the fields we need,\n",
    "- produces a clean dictionary for the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "510f35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_and_retrieval = {\n",
    "    \"name\": lambda x: x[\"name\"],\n",
    "    \"context\": lambda x: x[\"context\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b928eb0",
   "metadata": {},
   "source": [
    "This step does not generate new information.\n",
    "It only **selects and forwards** existing values.\n",
    "\n",
    "This pattern appears very often in agentic systems:\n",
    "- passing user input,\n",
    "- passing tool outputs,\n",
    "- passing retrieved context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e29e028",
   "metadata": {},
   "source": [
    "#### Step 3 â€” Compose the Full Chain\n",
    "\n",
    "The data flow is now explicit:\n",
    "\n",
    "- the input dictionary enters the setup step,\n",
    "- the setup step prepares the prompt variables,\n",
    "- the prompt formats a message,\n",
    "- the model generates text,\n",
    "- the parser extracts a clean string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faba5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = setup_and_retrieval | promp_template | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97d3a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Biography Generation -----\n",
      "Input: {'name': 'Albert Einstein', 'context': 'the theory of relativity'}\n",
      "\n",
      "Generated Biography:\n",
      "In the town of Ulm in Germany's land,  \n",
      "A genius was born, with a mind so grand.  \n",
      "Albert Einstein was his name,  \n",
      "And science was his claim to fame.  \n",
      "\n",
      "With wild hair and eyes so bright,  \n",
      "He pondered the stars, both day and night.  \n",
      "In physics, he found his true delight,  \n",
      "Unraveling mysteries, bringing truth to light.  \n",
      "\n",
      "E equals mc squared, he declared,  \n",
      "A theory of relativity that none compared.  \n",
      "Space and time, a cosmic dance,  \n",
      "He changed our view with a daring glance.  \n",
      "\n",
      "Though his mind was vast, his heart was kind,  \n",
      "For peace and justice, he was inclined.  \n",
      "In a world of chaos, he sought to find,  \n",
      "A path of wisdom for all of humankind.  \n",
      "\n",
      "From Germany to Princeton, his journey went,  \n",
      "A life of brilliance, fully spent.  \n",
      "Albert Einstein, a name we revere,  \n",
      "A legacy of knowledge, forever clear.  \n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"name\": \"Albert Einstein\",\n",
    "    \"context\": \"the theory of relativity\"\n",
    "}\n",
    "\n",
    "result = chain.invoke(input_data)\n",
    "\n",
    "print(\"----- Biography Generation -----\")\n",
    "print(f\"Input: {input_data}\")\n",
    "print(\"\\nGenerated Biography:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a62d9c",
   "metadata": {},
   "source": [
    "> **What to Take Away ?**\n",
    "\n",
    "- The chain does not depend on where the input comes from.\n",
    "- Each step has a clear responsibility.\n",
    "- Data preparation is explicit and readable.\n",
    "\n",
    "This separation becomes essential when building agents:\n",
    "reasoning, tools, and memory all rely on the same idea of controlled data flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308fee8",
   "metadata": {},
   "source": [
    "## Parallel Processing with RunnableParallel\n",
    "\n",
    "Until now, all chains followed a linear path:\n",
    "each component processed the output of the previous one.\n",
    "\n",
    "Agentic systems often need a different structure.\n",
    "They must look at the **same input from several angles at once**.\n",
    "\n",
    "Typical examples include:\n",
    "- producing a summary and an analysis in parallel,\n",
    "- extracting facts while keeping the original context,\n",
    "- generating multiple candidates before making a decision.\n",
    "\n",
    "LCEL supports this pattern through **RunnableParallel**.\n",
    "It allows one input to feed several branches at the same time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b902131",
   "metadata": {},
   "source": [
    "To illustrate this idea, we will reuse a single language model,\n",
    "but ask it to perform **different tasks in parallel**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8460be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda3baf5",
   "metadata": {},
   "source": [
    "Each branch of the pipeline is defined by its own prompt.\n",
    "All of them will receive the **same input dictionary**,\n",
    "but they will produce different kinds of outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358406d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a short summary about {topic}.\"\n",
    ")\n",
    "\n",
    "key_points_prompt = ChatPromptTemplate.from_template(\n",
    "    \"List three key points about {topic}.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ae90e",
   "metadata": {},
   "source": [
    "These branches are then combined into a single parallel structure.\n",
    "`RunnableParallel` takes care of sending the input to all branches\n",
    "and collecting their outputs in a structured way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cc5272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel(\n",
    "    summary=summary_prompt | model | output_parser,\n",
    "    key_points=key_points_prompt | model | output_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03fad3b",
   "metadata": {},
   "source": [
    "When the chain is invoked, both branches are executed independently.\n",
    "The result is a dictionary that groups all outputs under clear keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2d14770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Parallel Processing Result -----\n",
      "\n",
      "Summary:\n",
      "Agentic AI refers to artificial intelligence systems that exhibit characteristics of agency, meaning they can autonomously perceive environments, make decisions, and take actions to achieve specific goals. Often designed to simulate decision-making processes similar to those of humans or animals, agentic AI systems have applications across various domains, such as robotics, autonomous vehicles, virtual personal assistants, and complex simulations. The development of agentic AI involves interdisciplinary approaches, integrating advancements in machine learning, cognitive science, and robotics. With the potential to perform tasks without direct human intervention, agentic AI raises important ethical and safety considerations, including concerns about accountability, transparency, and the impact on employment and society.\n",
      "\n",
      "Key Points:\n",
      "Agentic AI refers to artificial intelligence systems endowed with some level of agency, meaning they can make decisions and take actions autonomously based on their programming and the environment. Here are three key points about Agentic AI:\n",
      "\n",
      "1. **Autonomy and Decision-Making**: Agentic AI systems are designed to operate with a certain degree of independence. They can analyze data, make decisions, and perform actions without needing direct human intervention for each step. This capability allows them to adapt to changes in their environment and execute tasks more efficiently.\n",
      "\n",
      "2. **Ethical and Safety Considerations**: The autonomous nature of Agentic AI raises important ethical and safety concerns. It is crucial to ensure that these systems align with human values and societal norms, and that they are safe to interact with real-world environments. Developers must address issues such as accountability, transparency, and bias to prevent undesirable outcomes.\n",
      "\n",
      "3. **Applications Across Various Domains**: Agentic AI can be applied in numerous fields, including autonomous vehicles, robotics, smart assistants, and industrial automation. In each of these areas, Agentic AI has the potential to enhance productivity, improve efficiency, and enable new capabilities that were not feasible with traditional automation methods.\n"
     ]
    }
   ],
   "source": [
    "input_data = {\"topic\": \"Agentic AI\"}\n",
    "result = parallel_chain.invoke(input_data)\n",
    "\n",
    "print(\"----- Parallel Processing Result -----\")\n",
    "print(\"\\nSummary:\")\n",
    "print(result[\"summary\"])\n",
    "\n",
    "print(\"\\nKey Points:\")\n",
    "print(result[\"key_points\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761770ea",
   "metadata": {},
   "source": [
    "The data flow is now easy to reason about:\n",
    "\n",
    "- one input enters the system,\n",
    "- several transformations happen in parallel,\n",
    "- results are gathered without conflict.\n",
    "\n",
    "This structured parallelism is essential for agents.\n",
    "Before acting, an agent may need to:\n",
    "- analyze a situation,\n",
    "- check constraints,\n",
    "- generate possible actions.\n",
    "\n",
    "`RunnableParallel` makes this pattern explicit and manageable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
